{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "id": "l3O6rs5JTwjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "bNH547hSUwjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Paleuna/CS639.git\n",
        "!git clone https://github.com/DrSleep/DenseTorch.git\n",
        "!pip install -e /content/DenseTorch\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "4yhqlXAV3-VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/DenseTorch"
      ],
      "metadata": {
        "id": "ak1W15qfm5ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import densetorch"
      ],
      "metadata": {
        "id": "VrGOaexKm6ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# below is the linux command to download the required dataset\n",
        "# we already downloaded the dataset to our google drive\n",
        "# the command is for reference"
      ],
      "metadata": {
        "id": "CjAkzm9Hvvye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/MyDrive/CS639/data1/Cityscapes/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCQL_9REfWLo",
        "outputId": "f1f03abc-7128-4f64-da2c-d54e734e89d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CS639/data1/Cityscapes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=Paleuna&password=Abc123456!&submit=Login' \"https://www.cityscapes-dataset.com/login/\"\n",
        "!wget --load-cookies cookies.txt --content-disposition \"https://www.cityscapes-dataset.com/file-handling/?packageID=1\"\n",
        "!wget --load-cookies cookies.txt --content-disposition \"https://www.cityscapes-dataset.com/file-handling/?packageID=3\"\n",
        "!unzip gtFine_trainvaltest.zip \n",
        "!rm gtFine_trainvaltest.zip \n",
        "!unzip leftImg8bit_trainvaltest.zip\n",
        "!rm leftImg8bit_trainvaltest.zip"
      ],
      "metadata": {
        "id": "wXfZPrX_qwfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/MyDrive/CS639/data1/"
      ],
      "metadata": {
        "id": "gfMbx_bjPWgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt --content-disposition \"https://www.cityscapes-dataset.com/file-handling/?packageID=31\"\n",
        "!unzip leftImg8bit_trainval_foggyDBF.zip\n",
        "!rm leftImg8bit_trainval_foggyDBF.zip\n",
        "\n",
        "!wget \"https://data.vision.ee.ethz.ch/csakarid/shared/Model_adaptation_SFSU_dense/Downloads/Foggy_Zurich.zip\"\n",
        "!unzip Foggy_Zurich.zip\n",
        "!rm Foggy_Zurich.zip\n",
        "\n",
        "!wget \"https://data.vision.ee.ethz.ch/csakarid/shared/SFSU_synthetic/Downloads/Foggy_Driving.zip\"\n",
        "!unzip Foggy_Driving.zip\n",
        "!rm Foggy_Driving.zip"
      ],
      "metadata": {
        "id": "WrZe5uHjlOQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here is the main code:"
      ],
      "metadata": {
        "id": "xXZCZUwRY-6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CS639/fifo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCxTgxJLw14Z",
        "outputId": "9718269a-e2ab-4b28-d1bb-e7355864830d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CS639/fifo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad \n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from packaging import version\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "\n",
        "from model.refinenetlw import rf_lw101\n",
        "from model.fogpassfilter import FogPassFilter_conv1, FogPassFilter_res1\n",
        "from utils.losses import CrossEntropy2d\n",
        "from dataset.paired_cityscapes import Pairedcityscapes\n",
        "from dataset.Foggy_Zurich import foggyzurichDataSet\n",
        "from utils.optimisers import get_optimisers, get_lr_schedulers\n",
        "from pytorch_metric_learning import losses\n",
        "from pytorch_metric_learning.distances import CosineSimilarity\n",
        "from pytorch_metric_learning.reducers import MeanReducer"
      ],
      "metadata": {
        "id": "WZ-2w0BpvMde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#config of the training process\n",
        "\n",
        "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "BETA = 0.005\n",
        "BATCH_SIZE = 4\n",
        "ITER_SIZE = 1\n",
        "NUM_WORKERS = 4\n",
        "DATA_DIRECTORY ='/content/gdrive/MyDrive/CS639/data1'\n",
        "DATA_LIST_PATH = f'./dataset/cityscapes_list/train_foggy_{BETA}.txt'\n",
        "DATA_CITY_PATH = './dataset/cityscapes_list/clear_lindau.txt'\n",
        "INPUT_SIZE = '2048,1024'\n",
        "DATA_DIRECTORY_CWSF = '/content/gdrive/MyDrive/CS639/data1/Cityscapes'\n",
        "DATA_LIST_PATH_CWSF = './dataset/cityscapes_list/train_origin.txt'\n",
        "DATA_LIST_RF = '/content/gdrive/MyDrive/CS639/data1/Foggy_Zurich/lists_file_names/RGB_sum_filenames.txt'\n",
        "DATA_DIR = '/content/gdrive/MyDrive/CS639/data1'\n",
        "INPUT_SIZE_RF = '1920,1080'\n",
        "NUM_CLASSES = 19 \n",
        "NUM_STEPS = 20000\n",
        "NUM_STEPS_STOP = 13000  # early stopping\n",
        "RANDOM_SEED = 1234\n",
        "RESTORE_FROM = '/content/gdrive/MyDrive/CS639/Cityscapes_pretrained_model.pth'\n",
        "RESTORE_FROM_fogpass = '/content/gdrive/MyDrive/CS639/FogPassFilter_pretrained.pth'\n",
        "SAVE_PRED_EVERY = 100\n",
        "SNAPSHOT_DIR = f'/content/gdrive/MyDrive/CS639/data1/snapshots/Model' \n",
        "FILE_NAME = 'Original_Model'  \n",
        "SET = 'train'\n",
        "\n",
        "def get_arguments():\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description=\"MyModel\")\n",
        "    parser.add_argument(\"--img-mean\", type=float, default=IMG_MEAN)\n",
        "    parser.add_argument(\"--batch-size\", type=int, default=BATCH_SIZE)\n",
        "    parser.add_argument(\"--iter-size\", type=int, default=ITER_SIZE)\n",
        "    parser.add_argument(\"--num-workers\", type=int, default=NUM_WORKERS)\n",
        "    parser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY)\n",
        "    parser.add_argument(\"--data-list\", type=str, default=DATA_LIST_PATH)\n",
        "    parser.add_argument(\"--data-city-list\", type=str, default = DATA_CITY_PATH)\n",
        "    parser.add_argument(\"--data-list-rf\", type=str, default=DATA_LIST_RF)    \n",
        "    parser.add_argument(\"--input-size\", type=str, default=INPUT_SIZE)\n",
        "    parser.add_argument(\"--input-size-rf\", type=str, default=INPUT_SIZE_RF)\n",
        "    parser.add_argument(\"--data-dir-cwsf\", type=str, default=DATA_DIRECTORY_CWSF)\n",
        "    parser.add_argument(\"--data-list-cwsf\", type=str, default=DATA_LIST_PATH_CWSF)\n",
        "    parser.add_argument(\"--data-dir-rf\", type=str, default=DATA_DIR)\n",
        "    parser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES)\n",
        "    parser.add_argument(\"--num-steps\", type=int, default=NUM_STEPS)\n",
        "    parser.add_argument(\"--num-steps-stop\", type=int, default=NUM_STEPS_STOP)\n",
        "    parser.add_argument(\"--random-seed\", type=int, default=RANDOM_SEED)\n",
        "    parser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM)\n",
        "    parser.add_argument(\"--restore-from-fogpass\", type=str, default=RESTORE_FROM_fogpass)\n",
        "    parser.add_argument(\"--save-pred-every\", type=int, default=SAVE_PRED_EVERY)\n",
        "    parser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR)\n",
        "    parser.add_argument(\"--gpu\", type=int, default=0)\n",
        "    parser.add_argument(\"--set\", type=str, default=SET)\n",
        "    parser.add_argument(\"--lambda-fsm\", type=float, default=0.0000001)\n",
        "    parser.add_argument(\"--lambda-con\", type=float, default=0.0001)\n",
        "    parser.add_argument(\"--file-name\", type=str, default = FILE_NAME)\n",
        "    parser.add_argument(\"--modeltrain\", type=str, default = 'train')\n",
        "    return parser.parse_args(args=[])\n",
        "\n",
        "args = get_arguments()\n"
      ],
      "metadata": {
        "id": "FpKqr44Tk3L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_calc(pred, label, gpu):\n",
        "    label = Variable(label.long()).cuda(gpu)\n",
        "    criterion = CrossEntropy2d().cuda(gpu)\n",
        "    return criterion(pred, label)\n",
        "\n",
        "def gram_matrix(tensor):\n",
        "    d, h, w = tensor.size()\n",
        "    tensor = tensor.view(d, h*w)\n",
        "    gram = torch.mm(tensor, tensor.t())\n",
        "    return gram\n",
        "\n",
        "def make_list(x):\n",
        "    \"\"\"Returns the given input as a list.\"\"\"\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    elif isinstance(x, tuple):\n",
        "        return list(x)\n",
        "    else:\n",
        "        return [x]\n",
        "\n",
        "#get argument from the config and update the random seed\n",
        "args = get_arguments()\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(args.random_seed)\n",
        "np.random.seed(args.random_seed)\n",
        "torch.manual_seed(args.random_seed)\n",
        "torch.cuda.manual_seed_all(args.random_seed)\n",
        "torch.cuda.manual_seed(args.random_seed)\n",
        "\n",
        "w, h = map(int, args.input_size.split(','))\n",
        "w_r, h_r = map(int, args.input_size_rf.split(',')) \n",
        "\n",
        "input_size = (w, h)\n",
        "input_size_rf = (w_r, h_r)   \n",
        "\n",
        "#load the pretrain model for the segmentation network\n",
        "restore = torch.load(args.restore_from)\n",
        "model = rf_lw101(num_classes=args.num_classes)\n",
        "model.load_state_dict(restore['state_dict'])\n",
        "start_iter = 0\n",
        "\n",
        "#gpu stuff\n",
        "cudnn.enabled = True\n",
        "gpu = args.gpu\n",
        "model.train()\n",
        "model.cuda(args.gpu)\n",
        "\n",
        "lr_fpf1 = 1e-3 \n",
        "lr_fpf2 = 1e-3\n",
        "\n",
        "if args.modeltrain=='train':\n",
        "    lr_fpf1 = 5e-4\n",
        "\n",
        "#define the fog pass filter\n",
        "FogPassFilter1 = FogPassFilter_conv1(2080)\n",
        "FogPassFilter1_optimizer = torch.optim.Adamax([p for p in FogPassFilter1.parameters() if p.requires_grad == True], lr=lr_fpf1)\n",
        "FogPassFilter1.cuda(args.gpu)\n",
        "FogPassFilter2 = FogPassFilter_res1(32896)\n",
        "FogPassFilter2_optimizer = torch.optim.Adamax([p for p in FogPassFilter2.parameters() if p.requires_grad == True], lr=lr_fpf2)\n",
        "FogPassFilter2.cuda(args.gpu)\n",
        "\n",
        "#load the pretrained model for the two filter\n",
        "restore = torch.load(args.restore_from_fogpass)\n",
        "FogPassFilter1.load_state_dict(restore['fogpass1_state_dict'])\n",
        "FogPassFilter2.load_state_dict(restore['fogpass2_state_dict'])\n",
        "\n",
        "\n",
        "fogpassfilter_loss = losses.ContrastiveLoss(\n",
        "    pos_margin=0.1,\n",
        "    neg_margin=0.1,\n",
        "    distance=CosineSimilarity(),\n",
        "    reducer=MeanReducer()\n",
        ")\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "if not os.path.exists(args.snapshot_dir):\n",
        "    os.makedirs(args.snapshot_dir)\n",
        "\n",
        "max_iters = args.num_steps * args.iter_size * args.batch_size\n",
        "\n",
        "#load the dataset (four datasets)\n",
        "cwsf_pair_loader = data.DataLoader(\n",
        "    Pairedcityscapes(args.data_dir, args.data_dir_cwsf, args.data_list, args.data_list_cwsf, max_iters=max_iters, mean=IMG_MEAN, set=args.set), \n",
        "    batch_size=args.batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=args.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "rf_loader = data.DataLoader(\n",
        "    foggyzurichDataSet(args.data_dir_rf, args.data_list_rf, max_iters=max_iters,mean=IMG_MEAN, set=args.set),\n",
        "    batch_size=args.batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=args.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "cwsf_pair_loader_fogpass = data.DataLoader(\n",
        "    Pairedcityscapes(args.data_dir, args.data_dir_cwsf, args.data_list, args.data_list_cwsf,max_iters=max_iters,mean=IMG_MEAN, set=args.set), \n",
        "    batch_size=args.batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=args.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "rf_loader_fogpass = data.DataLoader(\n",
        "    foggyzurichDataSet(args.data_dir_rf, args.data_list_rf,max_iters=max_iters,mean=IMG_MEAN, set=args.set), \n",
        "    batch_size=args.batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=args.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "#make the data be a interator\n",
        "rf_loader_iter = enumerate(rf_loader)\n",
        "cwsf_pair_loader_iter = enumerate(cwsf_pair_loader)\n",
        "cwsf_pair_loader_iter_fogpass = enumerate(cwsf_pair_loader_fogpass)\n",
        "rf_loader_iter_fogpass = enumerate(rf_loader_fogpass)\n",
        "\n",
        "#optimization setting\n",
        "optimisers = get_optimisers(\n",
        "    model=model,\n",
        "    enc_optim_type=\"sgd\",\n",
        "    enc_lr=6e-4,\n",
        "    enc_weight_decay=1e-5,\n",
        "    enc_momentum=0.9,\n",
        "    dec_optim_type=\"sgd\",\n",
        "    dec_lr=6e-3,\n",
        "    dec_weight_decay=1e-5,\n",
        "    dec_momentum=0.9,\n",
        ")\n",
        "\n",
        "#learning setting\n",
        "schedulers = get_lr_schedulers(\n",
        "    enc_optim=optimisers[0],\n",
        "    dec_optim=optimisers[1],\n",
        "    enc_lr_gamma=0.5,\n",
        "    dec_lr_gamma=0.5,\n",
        "    enc_scheduler_type=\"multistep\",\n",
        "    dec_scheduler_type=\"multistep\",\n",
        "    epochs_per_stage=(100, 100, 100),\n",
        ")\n",
        "\n",
        "opts = make_list(optimisers)\n",
        "kl_loss = torch.nn.KLDivLoss(reduction='batchmean')\n",
        "m = nn.Softmax(dim=1)\n",
        "log_m = nn.LogSoftmax(dim=1)    \n",
        "\n",
        "#start training\n",
        "for i_iter in tqdm(range(start_iter, args.num_steps)): \n",
        "    loss_seg_cw_value = 0\n",
        "    loss_seg_sf_value = 0\n",
        "    loss_fsm_value = 0\n",
        "    loss_con_value = 0\n",
        "\n",
        "    for opt in opts:\n",
        "        opt.zero_grad()\n",
        "\n",
        "    for sub_i in range(args.iter_size):\n",
        "        \n",
        "        # train fog-pass filter\n",
        "        # and freeze the segmentation network\n",
        "        model.eval()\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in FogPassFilter1.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in FogPassFilter2.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        _, batch = cwsf_pair_loader_iter_fogpass.__next__()\n",
        "        sf_image, cw_image, label, size, sf_name, cw_name = batch\n",
        "        interp = nn.Upsample(size=(size[0][0],size[0][1]), mode='bilinear')\n",
        "        \n",
        "        _, batch_rf = rf_loader_iter_fogpass.__next__()\n",
        "        rf_img,rf_size, rf_name = batch_rf\n",
        "        img_rf = Variable(rf_img).cuda(args.gpu)\n",
        "        feature_rf0, feature_rf1, feature_rf2, feature_rf3, feature_rf4, feature_rf5 = model(img_rf) \n",
        "\n",
        "        images = Variable(sf_image).cuda(args.gpu)\n",
        "        feature_sf0,feature_sf1,feature_sf2, feature_sf3,feature_sf4,feature_sf5 = model(images)\n",
        "\n",
        "        images_cw = Variable(cw_image).cuda(args.gpu)\n",
        "        feature_cw0, feature_cw1, feature_cw2, feature_cw3, feature_cw4, feature_cw5 = model(images_cw)\n",
        "\n",
        "        fsm_weights = {'layer0':0.5, 'layer1':0.5}\n",
        "        sf_features = {'layer0':feature_sf0, 'layer1':feature_sf1}                \n",
        "        cw_features = {'layer0':feature_cw0, 'layer1':feature_cw1}\n",
        "        rf_features = {'layer0':feature_rf0, 'layer1':feature_rf1}\n",
        "\n",
        "        total_fpf_loss = 0\n",
        "\n",
        "        for idx, layer in enumerate(fsm_weights):\n",
        "            cw_feature = cw_features[layer]\n",
        "            sf_feature = sf_features[layer]    \n",
        "            rf_feature = rf_features[layer]      \n",
        "            fog_pass_filter_loss = 0 \n",
        "            \n",
        "            if idx == 0:\n",
        "                fogpassfilter = FogPassFilter1\n",
        "                fogpassfilter_optimizer = FogPassFilter1_optimizer\n",
        "            elif idx == 1:\n",
        "                fogpassfilter = FogPassFilter2\n",
        "                fogpassfilter_optimizer = FogPassFilter2_optimizer\n",
        "\n",
        "            fogpassfilter.train()  \n",
        "            fogpassfilter_optimizer.zero_grad()\n",
        "            \n",
        "            sf_gram = [0]*args.batch_size\n",
        "            cw_gram = [0]*args.batch_size\n",
        "            rf_gram = [0]*args.batch_size \n",
        "            vector_sf_gram = [0]*args.batch_size\n",
        "            vector_cw_gram = [0]*args.batch_size\n",
        "            vector_rf_gram  = [0]*args.batch_size\n",
        "            fog_factor_sf = [0]*args.batch_size\n",
        "            fog_factor_cw = [0]*args.batch_size\n",
        "            fog_factor_rf = [0]*args.batch_size\n",
        "\n",
        "            for batch_idx in range(args.batch_size):\n",
        "                sf_gram[batch_idx] = gram_matrix(sf_feature[batch_idx])\n",
        "                cw_gram[batch_idx] = gram_matrix(cw_feature[batch_idx])\n",
        "                rf_gram[batch_idx] = gram_matrix(rf_feature[batch_idx])\n",
        "\n",
        "                vector_sf_gram[batch_idx] = Variable(sf_gram[batch_idx][torch.triu(torch.ones(sf_gram[batch_idx].size()[0], sf_gram[batch_idx].size()[1])) == 1], requires_grad=True)\n",
        "                vector_cw_gram[batch_idx] = Variable(cw_gram[batch_idx][torch.triu(torch.ones(cw_gram[batch_idx].size()[0], cw_gram[batch_idx].size()[1])) == 1], requires_grad=True)\n",
        "                vector_rf_gram[batch_idx] = Variable(rf_gram[batch_idx][torch.triu(torch.ones(rf_gram[batch_idx].size()[0], rf_gram[batch_idx].size()[1])) == 1], requires_grad=True)\n",
        "\n",
        "                fog_factor_sf[batch_idx] = fogpassfilter(vector_sf_gram[batch_idx])\n",
        "                fog_factor_cw[batch_idx] = fogpassfilter(vector_cw_gram[batch_idx])\n",
        "                fog_factor_rf[batch_idx] = fogpassfilter(vector_rf_gram[batch_idx])                                                                                                                                                                                                \n",
        "\n",
        "            fog_factor_embeddings = torch.cat((torch.unsqueeze(fog_factor_sf[0],0),torch.unsqueeze(fog_factor_cw[0],0),torch.unsqueeze(fog_factor_rf[0],0),\n",
        "                                                torch.unsqueeze(fog_factor_sf[1],0),torch.unsqueeze(fog_factor_cw[1],0),torch.unsqueeze(fog_factor_rf[1],0),\n",
        "                                                torch.unsqueeze(fog_factor_sf[2],0),torch.unsqueeze(fog_factor_cw[2],0),torch.unsqueeze(fog_factor_rf[2],0),\n",
        "                                                torch.unsqueeze(fog_factor_sf[3],0),torch.unsqueeze(fog_factor_cw[3],0),torch.unsqueeze(fog_factor_rf[3],0)),0)\n",
        "\n",
        "            fog_factor_embeddings_norm = torch.norm(fog_factor_embeddings, p=2, dim=1).detach()\n",
        "            size_fog_factor = fog_factor_embeddings.size()\n",
        "            fog_factor_embeddings = fog_factor_embeddings.div(fog_factor_embeddings_norm.expand(size_fog_factor[1],12).t())\n",
        "            fog_factor_labels = torch.LongTensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n",
        "            fog_pass_filter_loss = fogpassfilter_loss(fog_factor_embeddings,fog_factor_labels)\n",
        "\n",
        "            total_fpf_loss +=  fog_pass_filter_loss \n",
        "\n",
        "        total_fpf_loss.backward(retain_graph=False)\n",
        "\n",
        "        if args.modeltrain=='train':\n",
        "            # train segmentation network\n",
        "            # freeze the fog pass filter\n",
        "\n",
        "            model.train()\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = True\n",
        "            for param in FogPassFilter1.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in FogPassFilter2.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            _, batch = cwsf_pair_loader_iter.__next__()\n",
        "            sf_image, cw_image, label, size, sf_name, cw_name = batch\n",
        "\n",
        "            interp = nn.Upsample(size=(size[0][0],size[0][1]), mode='bilinear')\n",
        "\n",
        "            if i_iter % 3 == 0:\n",
        "                images_sf = Variable(sf_image).cuda(args.gpu)\n",
        "                feature_sf0,feature_sf1,feature_sf2, feature_sf3,feature_sf4,feature_sf5 = model(images_sf)\n",
        "                pred_sf5 = interp(feature_sf5)\n",
        "                loss_seg_sf = loss_calc(pred_sf5, label, args.gpu)\n",
        "                images_cw = Variable(cw_image).cuda(args.gpu)\n",
        "                feature_cw0, feature_cw1, feature_cw2, feature_cw3, feature_cw4, feature_cw5 = model(images_cw)\n",
        "                pred_cw5 = interp(feature_cw5)\n",
        "                feature_cw5_logsoftmax = log_m(feature_cw5)\n",
        "                feature_sf5_softmax = m(feature_sf5)\n",
        "                feature_sf5_logsoftmax = log_m(feature_sf5)\n",
        "                feature_cw5_softmax = m(feature_cw5)\n",
        "                loss_con = kl_loss(feature_sf5_logsoftmax, feature_cw5_softmax)\n",
        "                loss_seg_cw = loss_calc(pred_cw5, label, args.gpu)     \n",
        "                fsm_weights = {'layer0':0.5, 'layer1':0.5}\n",
        "                sf_features = {'layer0':feature_sf0, 'layer1':feature_sf1}                \n",
        "                cw_features = {'layer0':feature_cw0, 'layer1':feature_cw1}\n",
        "\n",
        "            if i_iter % 3 == 1:\n",
        "                _, batch_rf = rf_loader_iter.__next__()\n",
        "                rf_img,rf_size, rf_name = batch_rf\n",
        "                images_sf = Variable(sf_image).cuda(args.gpu)\n",
        "                feature_sf0,feature_sf1,feature_sf2, feature_sf3,feature_sf4,feature_sf5 = model(images_sf)\n",
        "                pred_sf5 = interp(feature_sf5)\n",
        "                loss_seg_sf = loss_calc(pred_sf5, label, args.gpu)       \n",
        "                loss_seg_cw = 0   \n",
        "                loss_con = 0\n",
        "                img_rf = Variable(rf_img).cuda(args.gpu)\n",
        "                feature_rf0, feature_rf1, feature_rf2, feature_rf3, feature_rf4, feature_rf5 = model(img_rf)    \n",
        "                rf_features = {'layer0':feature_rf0, 'layer1':feature_rf1}\n",
        "                sf_features = {'layer0':feature_sf0, 'layer1':feature_sf1}\n",
        "                fsm_weights = {'layer0':0.5, 'layer1':0.5}\n",
        "            \n",
        "            if i_iter % 3 == 2:\n",
        "                _, batch_rf = rf_loader_iter.__next__()\n",
        "                rf_img,rf_size, rf_name = batch_rf\n",
        "                images_cw = Variable(cw_image).cuda(args.gpu)\n",
        "                feature_cw0, feature_cw1, feature_cw2, feature_cw3, feature_cw4, feature_cw5 = model(images_cw)\n",
        "                pred_cw5 = interp(feature_cw5)\n",
        "                loss_seg_sf = 0\n",
        "                loss_con = 0\n",
        "                loss_seg_cw = loss_calc(pred_cw5, label, args.gpu)      \n",
        "                img_rf = Variable(rf_img).cuda(args.gpu)\n",
        "                feature_rf0, feature_rf1, feature_rf2, feature_rf3, feature_rf4, feature_rf5 = model(img_rf)                  \n",
        "                rf_features = {'layer0':feature_rf0, 'layer1':feature_rf1}\n",
        "                cw_features = {'layer0':feature_cw0, 'layer1':feature_cw1}\n",
        "                fsm_weights = {'layer0':0.5, 'layer1':0.5}\n",
        "\n",
        "            loss_fsm = 0\n",
        "            fog_pass_filter_loss = 0\n",
        "\n",
        "            for idx, layer in enumerate(fsm_weights):\n",
        "                # fog pass filter loss between different fog conditions a and b\n",
        "                if i_iter % 3 == 0:\n",
        "                    a_feature = cw_features[layer]\n",
        "                    b_feature = sf_features[layer]    \n",
        "                if i_iter % 3 == 1:\n",
        "                    a_feature = rf_features[layer]\n",
        "                    b_feature = sf_features[layer]\n",
        "                if i_iter % 3 == 2:\n",
        "                    a_feature = rf_features[layer]\n",
        "                    b_feature = cw_features[layer]   \n",
        "\n",
        "                layer_fsm_loss = 0\n",
        "                fog_pass_filter_loss = 0   \n",
        "                na,da,ha,wa = a_feature.size()\n",
        "                nb,db,hb,wb = b_feature.size()\n",
        "\n",
        "                if idx == 0:\n",
        "                    fogpassfilter = FogPassFilter1\n",
        "                    fogpassfilter_optimizer = FogPassFilter1_optimizer\n",
        "                elif idx == 1:\n",
        "                    fogpassfilter = FogPassFilter2\n",
        "                    fogpassfilter_optimizer = FogPassFilter2_optimizer\n",
        "\n",
        "                fogpassfilter.eval()\n",
        "\n",
        "                for batch_idx in range(4):\n",
        "                    b_gram = gram_matrix(b_feature[batch_idx])\n",
        "                    a_gram = gram_matrix(a_feature[batch_idx])\n",
        "\n",
        "                    if i_iter % 3 == 1 or i_iter % 3 == 2:\n",
        "                        a_gram = a_gram *(hb*wb)/(ha*wa)\n",
        "\n",
        "                    vector_b_gram = b_gram[torch.triu(torch.ones(b_gram.size()[0], b_gram.size()[1])).requires_grad_() == 1].requires_grad_()\n",
        "                    vector_a_gram = a_gram[torch.triu(torch.ones(a_gram.size()[0], a_gram.size()[1])).requires_grad_() == 1].requires_grad_()\n",
        "\n",
        "                    fog_factor_b = fogpassfilter(vector_b_gram)\n",
        "                    fog_factor_a = fogpassfilter(vector_a_gram)\n",
        "                    half = int(fog_factor_b.shape[0]/2)\n",
        "                    \n",
        "                    layer_fsm_loss += fsm_weights[layer]*torch.mean((fog_factor_b/(hb*wb) - fog_factor_a/(ha*wa))**2)/half/ b_feature.size(0)\n",
        "\n",
        "                loss_fsm += layer_fsm_loss / 4.\n",
        "\n",
        "            loss = loss_seg_sf + loss_seg_cw + args.lambda_fsm*loss_fsm + args.lambda_con*loss_con  \n",
        "            loss = loss / args.iter_size\n",
        "            loss.backward()\n",
        "\n",
        "            if loss_seg_cw != 0:\n",
        "                loss_seg_cw_value += loss_seg_cw.data.cpu().numpy() / args.iter_size\n",
        "            if loss_seg_sf != 0:\n",
        "                loss_seg_sf_value += loss_seg_sf.data.cpu().numpy() / args.iter_size\n",
        "            if loss_fsm != 0:\n",
        "                loss_fsm_value += loss_fsm.data.cpu().numpy() / args.iter_size\n",
        "            if loss_con != 0:\n",
        "                loss_con_value += loss_con.data.cpu().numpy() / args.iter_size   \n",
        "\n",
        "            for opt in opts:\n",
        "                opt.step()\n",
        "\n",
        "        FogPassFilter1_optimizer.step()\n",
        "        FogPassFilter2_optimizer.step()\n",
        "\n",
        "    now = datetime.now().strftime('%m-%d-%H-%M')    \n",
        "    run_name = f'{args.file_name}-{now}'\n",
        "\n",
        "    if i_iter < 20000:\n",
        "        save_pred_every = 5000\n",
        "        if args.modeltrain=='train':\n",
        "            save_pred_every = 2000\n",
        "    else:\n",
        "        save_pred_every = args.save_pred_every\n",
        "\n",
        "    if i_iter >= args.num_steps_stop - 1:\n",
        "        print('save model ..')\n",
        "        torch.save(model.state_dict(), osp.join(args.snapshot_dir, args.file_name + str(args.num_steps_stop) + '.pth'))\n",
        "        break\n",
        "    \n",
        "  \n",
        "    if args.modeltrain != 'train':\n",
        "        if i_iter == 5000:\n",
        "            torch.save({'state_dict':model.state_dict(),\n",
        "            'fogpass1_state_dict':FogPassFilter1.state_dict(),\n",
        "            'fogpass2_state_dict':FogPassFilter2.state_dict(),\n",
        "            'train_iter':i_iter,\n",
        "            'args':args\n",
        "            },osp.join(args.snapshot_dir, run_name)+'_fogpassfilter_'+str(i_iter)+'.pth')\n",
        "\n",
        "    if i_iter % save_pred_every == 0 and i_iter != 0:\n",
        "        print('taking snapshot ...')\n",
        "        save_dir = osp.join(f'./result/FIFO_model', args.file_name)\n",
        "        \n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        \n",
        "        torch.save({\n",
        "            'state_dict':model.state_dict(),\n",
        "            'fogpass1_state_dict':FogPassFilter1.state_dict(),\n",
        "            'fogpass2_state_dict':FogPassFilter2.state_dict(),\n",
        "            'train_iter':i_iter,\n",
        "            'args':args\n",
        "        },osp.join(args.snapshot_dir, run_name)+'_FIFO'+str(i_iter)+'.pth')\n",
        "            "
      ],
      "metadata": {
        "id": "lJYjJ5DWkZvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is the code for our preprocessing layer, do not need to be implement here\n",
        "# (we add the code in .py file in github)\n",
        "# just for show"
      ],
      "metadata": {
        "id": "GTtDYUtYgY5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import statistics\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "#Section 3\n",
        "def getDark(img,kernal_size):\n",
        "    dc = np.minimum(np.minimum(img[:,:,0],img[:,:,1]),img[:,:,2])\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(kernal_size,kernal_size))\n",
        "    dark = cv2.erode(dc,kernel)\n",
        "    return dark\n",
        "\n",
        "#Section 4.1\n",
        "def getTransmission(img,A,sz):\n",
        "    omega = 0.95;\n",
        "    \n",
        "    R = img[:,:,0] / A[0,0]\n",
        "    G = img[:,:,1] / A[0,1]\n",
        "    B = img[:,:,2] / A[0,2]\n",
        "\n",
        "    normalized = np.dstack((R,G,B)) \n",
        "\n",
        "    transmission = 1 - omega*getDark(normalized,sz)\n",
        "    return transmission\n",
        "\n",
        "#modified Section 4.2\n",
        "#inspired by https://github.com/martiansideofthemoon/blind-dehazing/blob/master/dark_prior/guidedfilter.py\n",
        "def Guidedfilter(img,transmission,filter_size=60,epsilion=0.0001):\n",
        "    imageMean= cv2.boxFilter(img,cv2.CV_64F,(filter_size, filter_size))\n",
        "    transMean = cv2.boxFilter(transmission, cv2.CV_64F,(filter_size, filter_size))\n",
        "    itMean = cv2.boxFilter(img*transmission,cv2.CV_64F,(filter_size, filter_size))\n",
        "    itCov = itMean - imageMean*transMean \n",
        "    imageVar   = cv2.boxFilter(img*img,cv2.CV_64F,(filter_size, filter_size))- imageMean*imageMean\n",
        "\n",
        "    a = itCov/(imageVar + epsilion)\n",
        "    b = transMean - a*imageMean\n",
        "\n",
        "    aMean = cv2.boxFilter(a,cv2.CV_64F,(filter_size, filter_size))\n",
        "    bMean = cv2.boxFilter(b,cv2.CV_64F,(filter_size, filter_size))\n",
        "\n",
        "    res = aMean*img + bMean\n",
        "    return res\n",
        "\n",
        "def TransmissionRefine(img,transmission):\n",
        "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    gray = np.float64(gray)/255\n",
        "    t = Guidedfilter(gray,transmission,filter_size=60,epsilion=0.0001)\n",
        "\n",
        "    return t;\n",
        "\n",
        "\n",
        "#Section 4.3\n",
        "def Recover(img,t,A,t_default = 0.1):\n",
        "    t = cv2.max(t,t_default)\n",
        "    R = (img[:,:,0]-A[0,0])/t + A[0,0]\n",
        "    G = (img[:,:,1]-A[0,1])/t + A[0,1]\n",
        "    B = (img[:,:,2]-A[0,2])/t + A[0,2]\n",
        "    recovered= np.dstack((R,G,B)) \n",
        "    return recovered\n",
        "\n",
        "#Section4.4\n",
        "def getA(img,dark):\n",
        "    pixelNum = img.shape[0] * img.shape[1]\n",
        "    selectedPixel = int(max(math.floor(pixelNum/1000),1)) #select at least 1 pixel\n",
        "    darkvector = np.reshape(dark,-1)\n",
        "    R = np.reshape(img[:,:,0],-1)\n",
        "    G = np.reshape(img[:,:,1],-1)\n",
        "    B = np.reshape(img[:,:,2],-1)\n",
        "    \n",
        "    idx = darkvector.argsort()\n",
        "    idx = idx[pixelNum-selectedPixel::]\n",
        "    A = np.zeros([1,3])\n",
        "    for i in range(0,selectedPixel):\n",
        "        A[0,0] = A[0,0] + R[idx[i]]\n",
        "        A[0,1] = A[0,1] + G[idx[i]]\n",
        "        A[0,2] = A[0,2] + B[idx[i]]\n",
        "    \n",
        "    A = A/selectedPixel\n",
        "    \n",
        "    return A\n",
        "\n",
        "                      \n",
        "def PreprocessingLayer(img):  #img should be a np array    \n",
        "    #bilateral filter        \n",
        "    img = cv2.bilateralFilter(img, 15, 75, 75)\n",
        "    #dehaze\n",
        "    dark = getDark(img,15)\n",
        "    A = getA(img,dark)\n",
        "    transmission = getTransmission(img,A,15)\n",
        "    transmissionBetter = TransmissionRefine(img,transmission)\n",
        "    res = Recover(img,transmissionBetter,A,0.1) + 50\n",
        "    # add 50 to increase the lightness\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "rCCMm7jta7_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CS639/fifo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT-jSM6xfPRc",
        "outputId": "0b68d3f3-7969-47c7-a37c-4a708ac95339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CS639/fifo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation of original model\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "DATA_DIRECTORY ='/content/gdrive/MyDrive/CS639/data1'\n",
        "DATA_CITY_PATH = './dataset/cityscapes_list/clear_lindau.txt'\n",
        "DATA_DIRECTORY_CITY = '/content/gdrive/MyDrive/CS639/data1/Cityscapes'\n",
        "DATA_LIST_PATH_EVAL = '/content/gdrive/MyDrive/CS639/data1/Foggy_Zurich/lists_file_names/RGB_testv2_filenames.txt'\n",
        "DATA_LIST_PATH_EVAL_FD ='./lists_file_names/leftImg8bit_testall_filenames.txt'\n",
        "DATA_LIST_PATH_EVAL_FDD ='./lists_file_names/leftImg8bit_testdense_filenames.txt' \n",
        "DATA_DIR_EVAL = '/content/gdrive/MyDrive/CS639/data1'\n",
        "DATA_DIR_EVAL_FD = '/content/gdrive/MyDrive/CS639/data1/Foggy_Driving'\n",
        "NUM_CLASSES = 19 \n",
        "RESTORE_FROM = '/content/gdrive/MyDrive/CS639/data1/snapshots/FIFO_model/Original_Model_20000.pth'\n",
        "SNAPSHOT_DIR = f'/content/gdrive/MyDrive/CS639/data1/snapshots/FIFO-val'\n",
        "GT_DIR_FZ = '/content/gdrive/MyDrive/CS639/data1/Foggy_Zurich'\n",
        "GT_DIR_FD = '/content/gdrive/MyDrive/CS639/data1/Foggy_Driving'\n",
        "GT_DIR_CLINDAU = '/content/gdrive/MyDrive/CS639/data1/Cityscapes/gtFine'\n",
        "SET = 'val'\n",
        "FILE_NAME = 'Evaluation_Results' \n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Evlauation\")\n",
        "    parser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY)\n",
        "    parser.add_argument(\"--data-city-list\", type=str, default = DATA_CITY_PATH)\n",
        "    parser.add_argument(\"--data-list-eval-fd\", type=str, default=DATA_LIST_PATH_EVAL_FD)      \n",
        "    parser.add_argument(\"--data-list-eval-fdd\", type=str, default=DATA_LIST_PATH_EVAL_FDD)             \n",
        "    parser.add_argument(\"--data-dir-city\", type=str, default=DATA_DIRECTORY_CITY)\n",
        "    parser.add_argument(\"--data-list-eval\", type=str, default=DATA_LIST_PATH_EVAL)\n",
        "    parser.add_argument(\"--data-dir-eval\", type=str, default=DATA_DIR_EVAL)\n",
        "    parser.add_argument(\"--data-dir-eval-fd\", type=str, default=DATA_DIR_EVAL_FD)\n",
        "    parser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES)\n",
        "    parser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM)    \n",
        "    parser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR)\n",
        "    parser.add_argument(\"--gpu\", type=int, default=0)\n",
        "    parser.add_argument(\"--set\", type=str, default=SET)\n",
        "    parser.add_argument(\"--file-name\", type=str, default=FILE_NAME)\n",
        "    parser.add_argument(\"--gt-dir-fz\", type=str, default=GT_DIR_FZ)\n",
        "    parser.add_argument(\"--gt-dir-fd\", type=str, default=GT_DIR_FD)\n",
        "    parser.add_argument(\"--gt-dir-clindau\", type=str, default=GT_DIR_CLINDAU)\n",
        "    parser.add_argument(\"--devkit-dir-fz\", default='/content/gdrive/MyDrive/CS639/data1/Foggy_Zurich/lists_file_names') \n",
        "    parser.add_argument(\"--devkit-dir-fd\", default='./lists_file_names') \n",
        "    parser.add_argument(\"--devkit-dir-clindau\", default='./dataset/cityscapes_list')\n",
        "    return parser.parse_args(args=[])\n",
        "\n",
        "args = get_arguments()\n",
        "\n"
      ],
      "metadata": {
        "id": "FMJbWZAeh4em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "from packaging import version\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from model.refinenetlw import rf_lw101\n",
        "from compute_iou import compute_mIoU\n",
        "from dataset.cityscapes_dataset import cityscapesDataSet\n",
        "from dataset.Foggy_Zurich_test import foggyzurichDataSet\n",
        "from dataset.foggy_driving import foggydrivingDataSet\n",
        "\n",
        "palette = [128, 64, 128, 244, 35, 232, 70, 70, 70, 102, 102, 156, 190, 153, 153, 153, 153, 153, 250, 170, 30,\n",
        "           220, 220, 0, 107, 142, 35, 152, 251, 152, 70, 130, 180, 220, 20, 60, 255, 0, 0, 0, 0, 142, 0, 0, 70,\n",
        "           0, 60, 100, 0, 80, 100, 0, 0, 230, 119, 11, 32]\n",
        "zero_pad = 256 * 3 - len(palette)\n",
        "\n",
        "for i in range(zero_pad):\n",
        "    palette.append(0)\n",
        "\n",
        "\n",
        "def colorize_mask(mask):\n",
        "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
        "    new_mask.putpalette(palette)\n",
        "    return new_mask\n",
        "\n",
        "args = get_arguments()\n",
        "\n",
        "#load the trained model\n",
        "restore = torch.load(args.restore_from)\n",
        "model = rf_lw101(num_classes=args.num_classes)\n",
        "\n",
        "model.load_state_dict(restore['state_dict'])\n",
        "start_iter = 0\n",
        "\n",
        "#the filepath of the results for different dataset\n",
        "save_dir_fz = osp.join(f'./result_FZ', args.file_name)\n",
        "save_dir_fd = osp.join(f'./result_FD', args.file_name)\n",
        "save_dir_fdd = osp.join(f'./result_FDD', args.file_name)\n",
        "save_dir_clindau = osp.join(f'./result_Clindau', args.file_name)      \n",
        "\n",
        "if not os.path.exists(save_dir_fz):\n",
        "    os.makedirs(save_dir_fz)\n",
        "if not os.path.exists(save_dir_fd):\n",
        "    os.makedirs(save_dir_fd)\n",
        "if not os.path.exists(save_dir_fdd):\n",
        "    os.makedirs(save_dir_fdd)\n",
        "if not os.path.exists(save_dir_clindau):\n",
        "    os.makedirs(save_dir_clindau)\n",
        "\n",
        "model.eval()\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device)\n",
        "\n",
        "testloader1 = data.DataLoader(foggyzurichDataSet(args.data_dir_eval, args.data_list_eval, crop_size=(1152, 648), mean=IMG_MEAN),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader2 = data.DataLoader(foggyzurichDataSet(args.data_dir_eval, args.data_list_eval, crop_size=(1536, 864), mean=IMG_MEAN),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader3 = data.DataLoader(foggyzurichDataSet(args.data_dir_eval, args.data_list_eval, crop_size=(1920, 1080), mean=IMG_MEAN),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "\n",
        "if version.parse(torch.__version__) >= version.parse('0.4.0'):\n",
        "    interp_eval = nn.Upsample(size=(1080,1920), mode='bilinear', align_corners=True)\n",
        "else:\n",
        "    interp_eval = nn.Upsample(size=(1080,1920), mode='bilinear')\n",
        "\n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "\n",
        "for index, batch1 in enumerate(testloader1):\n",
        "    image, label_test, _, name = batch1\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, label_test, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, label_test, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_fz, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_fz, name[:-4]))\n",
        "\n",
        "miou_fz = compute_mIoU(args.gt_dir_fz, save_dir_fz, args.devkit_dir_fz, 'FZ')\n",
        "\n",
        "#test in foggydrivingDataSet\n",
        "testloader1 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fdd, scale=1),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "\n",
        "testloader2 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fdd, scale=0.8),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "\n",
        "testloader3 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fdd, scale=0.6),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "for index, batch in enumerate(testloader1):\n",
        "    image, size, name = batch\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        interp_eval = nn.Upsample(size=(size[0][0],size[0][1]), mode='bilinear')\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_fdd, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_fdd, name[:-4]))\n",
        "miou_fdd = compute_mIoU(args.gt_dir_fd, save_dir_fdd, args.devkit_dir_fd, 'FDD')\n",
        "\n",
        "\n",
        "testloader1 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fd, scale=1),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "\n",
        "testloader2 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fd, scale=0.8),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "\n",
        "testloader3 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fd, scale=0.6),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "for index, batch in enumerate(testloader1):\n",
        "    image, size, name = batch\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        interp_eval = nn.Upsample(size=(size[0][0],size[0][1]), mode='bilinear')\n",
        "\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_fd, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_fd, name[:-4]))\n",
        "miou_fd = compute_mIoU(args.gt_dir_fd, save_dir_fd, args.devkit_dir_fd, 'FD')\n",
        "\n",
        "\n",
        "testloader1 = data.DataLoader(cityscapesDataSet(args.data_dir_city, args.data_city_list, crop_size = (2048, 1024), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                        batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader2 = data.DataLoader(cityscapesDataSet(args.data_dir_city, args.data_city_list, crop_size = (2048*0.8, 1024*0.8), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                        batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader3 = data.DataLoader(cityscapesDataSet(args.data_dir_city, args.data_city_list, crop_size = (2048*0.6, 1024*0.6), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                        batch_size=1, shuffle=False, pin_memory=True)   \n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "for index, batch in enumerate(testloader1):\n",
        "    image, size, name = batch\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        interp_eval = nn.Upsample(size=(1024, 2048), mode='bilinear')\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_clindau, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_clindau, name.split('.')[0]))\n",
        "\n",
        "miou_clindau = compute_mIoU(args.gt_dir_clindau, save_dir_clindau, args.devkit_dir_clindau, 'Clindau')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FZO371AgyHc",
        "outputId": "4de56dd8-9556-4d51-b9b0-85ebc4a95039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.torch/models/101_imagenet.pth.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on Foggy Zurich\n",
            "===> mIoU: 42.88\n",
            "Evaluation on Foggy Driving Dense\n",
            "===> mIoU: 38.66\n",
            "Evaluation on Foggy Driving\n",
            "===> mIoU: 46.9\n",
            "Evaluation on Cityscapes lindau 40\n",
            "===> mIoU: 67.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CS639/fifo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbHaxtt5E-bf",
        "outputId": "25360159-e979-45d8-bd9e-68ca8347400f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CS639/fifo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation of original model  with preprocessing layer\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "DATA_DIRECTORY ='/content/gdrive/MyDrive/CS639/data1'\n",
        "DATA_CITY_PATH = './dataset/cityscapes_list/clear_lindau.txt'\n",
        "DATA_DIRECTORY_CITY = '/content/gdrive/MyDrive/CS639/data1/Cityscapes'\n",
        "DATA_LIST_PATH_EVAL = '/content/gdrive/MyDrive/CS639/data1/Foggy_Zurich/lists_file_names/RGB_testv2_filenames.txt'\n",
        "DATA_LIST_PATH_EVAL_FD ='./lists_file_names/leftImg8bit_testall_filenames.txt'\n",
        "DATA_LIST_PATH_EVAL_FDD ='./lists_file_names/leftImg8bit_testdense_filenames.txt' \n",
        "DATA_DIR_EVAL = '/content/gdrive/MyDrive/CS639/data1'\n",
        "DATA_DIR_EVAL_FD = '/content/gdrive/MyDrive/CS639/data1/Foggy_Driving'\n",
        "NUM_CLASSES = 19 \n",
        "RESTORE_FROM = '/content/gdrive/MyDrive/CS639/data1/snapshots/FIFO_model/Original_Model_20000_pre.pth'\n",
        "SNAPSHOT_DIR = f'/content/gdrive/MyDrive/CS639/data1/snapshots/FIFO-val-pre'\n",
        "GT_DIR_FZ = '/content/gdrive/MyDrive/CS639/data1/Foggy_Zurich'\n",
        "GT_DIR_FD = '/content/gdrive/MyDrive/CS639/data1/Foggy_Driving'\n",
        "GT_DIR_CLINDAU = '/content/gdrive/MyDrive/CS639/data1/Cityscapes/gtFine'\n",
        "SET = 'val'\n",
        "FILE_NAME = 'Evaluation_Results_pre' \n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Evlauation\")\n",
        "    parser.add_argument(\"--data-dir\", type=str, default=DATA_DIRECTORY)\n",
        "    parser.add_argument(\"--data-city-list\", type=str, default = DATA_CITY_PATH)\n",
        "    parser.add_argument(\"--data-list-eval-fd\", type=str, default=DATA_LIST_PATH_EVAL_FD)      \n",
        "    parser.add_argument(\"--data-list-eval-fdd\", type=str, default=DATA_LIST_PATH_EVAL_FDD)             \n",
        "    parser.add_argument(\"--data-dir-city\", type=str, default=DATA_DIRECTORY_CITY)\n",
        "    parser.add_argument(\"--data-list-eval\", type=str, default=DATA_LIST_PATH_EVAL)\n",
        "    parser.add_argument(\"--data-dir-eval\", type=str, default=DATA_DIR_EVAL)\n",
        "    parser.add_argument(\"--data-dir-eval-fd\", type=str, default=DATA_DIR_EVAL_FD)\n",
        "    parser.add_argument(\"--num-classes\", type=int, default=NUM_CLASSES)\n",
        "    parser.add_argument(\"--restore-from\", type=str, default=RESTORE_FROM)    \n",
        "    parser.add_argument(\"--snapshot-dir\", type=str, default=SNAPSHOT_DIR)\n",
        "    parser.add_argument(\"--gpu\", type=int, default=0)\n",
        "    parser.add_argument(\"--set\", type=str, default=SET)\n",
        "    parser.add_argument(\"--file-name\", type=str, default=FILE_NAME)\n",
        "    parser.add_argument(\"--gt-dir-fz\", type=str, default=GT_DIR_FZ)\n",
        "    parser.add_argument(\"--gt-dir-fd\", type=str, default=GT_DIR_FD)\n",
        "    parser.add_argument(\"--gt-dir-clindau\", type=str, default=GT_DIR_CLINDAU)\n",
        "    parser.add_argument(\"--devkit-dir-fz\", default='/content/gdrive/MyDrive/CS639/data1/Foggy_Zurich/lists_file_names') \n",
        "    parser.add_argument(\"--devkit-dir-fd\", default='./lists_file_names') \n",
        "    parser.add_argument(\"--devkit-dir-clindau\", default='./dataset/cityscapes_list')\n",
        "    return parser.parse_args(args=[])\n",
        "\n",
        "args = get_arguments()\n"
      ],
      "metadata": {
        "id": "yyB1z9rUEJe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "from packaging import version\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from model.refinenetlw import rf_lw101\n",
        "from compute_iou import compute_mIoU\n",
        "from dataset.cityscapes_dataset_pre import cityscapesDataSet\n",
        "from dataset.Foggy_Zurich_test_pre import foggyzurichDataSet\n",
        "from dataset.foggy_driving_pre import foggydrivingDataSet\n",
        "\n",
        "palette = [128, 64, 128, 244, 35, 232, 70, 70, 70, 102, 102, 156, 190, 153, 153, 153, 153, 153, 250, 170, 30,\n",
        "           220, 220, 0, 107, 142, 35, 152, 251, 152, 70, 130, 180, 220, 20, 60, 255, 0, 0, 0, 0, 142, 0, 0, 70,\n",
        "           0, 60, 100, 0, 80, 100, 0, 0, 230, 119, 11, 32]\n",
        "zero_pad = 256 * 3 - len(palette)\n",
        "\n",
        "for i in range(zero_pad):\n",
        "    palette.append(0)\n",
        "\n",
        "\n",
        "def colorize_mask(mask):\n",
        "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
        "    new_mask.putpalette(palette)\n",
        "    return new_mask\n",
        "\n",
        "args = get_arguments()\n",
        "\n",
        "#load the trained model\n",
        "restore = torch.load(args.restore_from)\n",
        "model = rf_lw101(num_classes=args.num_classes)\n",
        "\n",
        "model.load_state_dict(restore['state_dict'])\n",
        "start_iter = 0\n",
        "\n",
        "#the filepath of the results for different dataset\n",
        "save_dir_fz = osp.join(f'./result_FZ', args.file_name)\n",
        "save_dir_fd = osp.join(f'./result_FD', args.file_name)\n",
        "save_dir_fdd = osp.join(f'./result_FDD', args.file_name)\n",
        "save_dir_clindau = osp.join(f'./result_Clindau', args.file_name)      \n",
        "\n",
        "if not os.path.exists(save_dir_fz):\n",
        "    os.makedirs(save_dir_fz)\n",
        "if not os.path.exists(save_dir_fd):\n",
        "    os.makedirs(save_dir_fd)\n",
        "if not os.path.exists(save_dir_fdd):\n",
        "    os.makedirs(save_dir_fdd)\n",
        "if not os.path.exists(save_dir_clindau):\n",
        "    os.makedirs(save_dir_clindau)\n",
        "\n",
        "model.eval()\n",
        "device = torch.device('cuda:0')\n",
        "model.to(device)\n",
        "\n",
        "testloader1 = data.DataLoader(foggyzurichDataSet(args.data_dir_eval, args.data_list_eval, crop_size=(1152, 648), mean=IMG_MEAN),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader2 = data.DataLoader(foggyzurichDataSet(args.data_dir_eval, args.data_list_eval, crop_size=(1536, 864), mean=IMG_MEAN),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader3 = data.DataLoader(foggyzurichDataSet(args.data_dir_eval, args.data_list_eval, crop_size=(1920, 1080), mean=IMG_MEAN),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "\n",
        "if version.parse(torch.__version__) >= version.parse('0.4.0'):\n",
        "    interp_eval = nn.Upsample(size=(1080,1920), mode='bilinear', align_corners=True)\n",
        "else:\n",
        "    interp_eval = nn.Upsample(size=(1080,1920), mode='bilinear')\n",
        "\n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "\n",
        "for index, batch1 in enumerate(testloader1):\n",
        "    image, label_test, _, name = batch1\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, label_test, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, label_test, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_fz, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_fz, name[:-4]))\n",
        "\n",
        "miou_fz = compute_mIoU(args.gt_dir_fz, save_dir_fz, args.devkit_dir_fz, 'FZ')\n",
        "\n",
        "#test in foggydrivingDataSet\n",
        "testloader1 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fdd, scale=1),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "\n",
        "testloader2 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fdd, scale=0.8),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "\n",
        "testloader3 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fdd, scale=0.6),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "for index, batch in enumerate(testloader1):\n",
        "    image, size, name = batch\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        interp_eval = nn.Upsample(size=(size[0][0],size[0][1]), mode='bilinear')\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_fdd, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_fdd, name[:-4]))\n",
        "miou_fdd = compute_mIoU(args.gt_dir_fd, save_dir_fdd, args.devkit_dir_fd, 'FDD')\n",
        "\n",
        "\n",
        "testloader1 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fd, scale=1),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "\n",
        "testloader2 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fd, scale=0.8),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "\n",
        "testloader3 = data.DataLoader(foggydrivingDataSet(args.data_dir_eval_fd, args.data_list_eval_fd, scale=0.6),\n",
        "                                batch_size=1, shuffle=False, pin_memory=True) \n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "for index, batch in enumerate(testloader1):\n",
        "    image, size, name = batch\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        interp_eval = nn.Upsample(size=(size[0][0],size[0][1]), mode='bilinear')\n",
        "\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_fd, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_fd, name[:-4]))\n",
        "miou_fd = compute_mIoU(args.gt_dir_fd, save_dir_fd, args.devkit_dir_fd, 'FD')\n",
        "\n",
        "\n",
        "testloader1 = data.DataLoader(cityscapesDataSet(args.data_dir_city, args.data_city_list, crop_size = (2048, 1024), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                        batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader2 = data.DataLoader(cityscapesDataSet(args.data_dir_city, args.data_city_list, crop_size = (2048*0.8, 1024*0.8), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                        batch_size=1, shuffle=False, pin_memory=True)\n",
        "testloader3 = data.DataLoader(cityscapesDataSet(args.data_dir_city, args.data_city_list, crop_size = (2048*0.6, 1024*0.6), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                        batch_size=1, shuffle=False, pin_memory=True)   \n",
        "testloader_iter2 = enumerate(testloader2)\n",
        "testloader_iter3 = enumerate(testloader3)\n",
        "\n",
        "for index, batch in enumerate(testloader1):\n",
        "    image, size, name = batch\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        interp_eval = nn.Upsample(size=(1024, 2048), mode='bilinear')\n",
        "        output_1 = interp_eval(output2)\n",
        "\n",
        "    _, batch2 = testloader_iter2.__next__()\n",
        "    image, _, name = batch2\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_2 = interp_eval(output2)\n",
        "\n",
        "    _, batch3 = testloader_iter3.__next__()    \n",
        "    image, _, name = batch3\n",
        "    with torch.no_grad():\n",
        "        output6, output3, output4, output5, output1, output2 = model(Variable(image).cuda(args.gpu))\n",
        "        output_3 = interp_eval(output2)\n",
        "\n",
        "    output = torch.cat([output_1,output_2,output_3])\n",
        "    output = torch.mean(output, dim=0)\n",
        "    output = output.cpu().numpy()\n",
        "    output = output.transpose(1,2,0)\n",
        "    output = np.asarray(np.argmax(output, axis=2), dtype=np.uint8)\n",
        "\n",
        "    output_col = colorize_mask(output)\n",
        "    output = Image.fromarray(output)\n",
        "\n",
        "    name = name[0].split('/')[-1]\n",
        "    output.save('%s/%s' % (save_dir_clindau, name))\n",
        "    output_col.save('%s/%s_color.png' % (save_dir_clindau, name.split('.')[0]))\n",
        "\n",
        "miou_clindau = compute_mIoU(args.gt_dir_clindau, save_dir_clindau, args.devkit_dir_clindau, 'Clindau')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj4vqrhkkkl6",
        "outputId": "36f2584c-570e-4ded-fb78-fcf3dc7856ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on Foggy Zurich\n",
            "===> mIoU: 41.42\n",
            "Evaluation on Foggy Driving Dense\n",
            "===> mIoU: 40.84\n",
            "Evaluation on Foggy Driving\n",
            "===> mIoU: 47.10\n",
            "Evaluation on Cityscapes lindau 40\n",
            "===> mIoU: 65.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QXvQmaDIUmso"
      }
    }
  ]
}